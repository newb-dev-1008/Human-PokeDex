{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Slow Fusion (Distributed Training).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newb-dev-1008/Human-PokeDex/blob/master/Slow%20Fusion%20-%20(Distributed%20Training).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62KJgqMP8xJ7"
      },
      "source": [
        "# Tests to try\n",
        "# 1. Change in number of images per box (16)\n",
        "# 2. Kernel sizes\n",
        "# 3. Addition of Residual blocks\n",
        "# 4. Change in number of images per layer (from 2 to 4) in the temporal dimension\n",
        "# 5. Check the code for prediction in x_test\n",
        "# 6. Check out the graphs per epoch you want to plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhX2WtX69IS-",
        "outputId": "e90d43e5-38dd-42e4-e7a3-5736d81132e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g9qBKCfzFtf"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2UAButA18i3",
        "outputId": "e14d4f02-1b8d-4c12-c037-7541963df9a5"
      },
      "source": [
        "# Check available TensorFlow devices\n",
        "from tensorflow import config\n",
        "config.list_physical_devices('GPU')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WetCIkKf1EiQ"
      },
      "source": [
        "inputData = \"/content/drive/MyDrive/Datasets/Annotated\"\n",
        "arrPaths = []\n",
        "arrLbls = []\n",
        "lbls = []\n",
        "temporal_dimension = 10\n",
        "labelNumber = {\n",
        "    'Abuse' : 0,\n",
        "    'Assault' : 1,\n",
        "    'Fighting' : 2,\n",
        "    'Normal' : 3,\n",
        "    'Robbery' : 4,\n",
        "    'Vandalism' : 5\n",
        "}\n",
        "\n",
        "for labelFolder in os.listdir(inputData):\n",
        "    labelFolderPath = (inputData + \"/\" + labelFolder)\n",
        "    \n",
        "    for clip in os.listdir(labelFolderPath):\n",
        "        count = 0\n",
        "        clipPath = (inputData + \"/\" + labelFolder + \"/\" + clip)\n",
        "        \n",
        "        for frame in range(count, len(os.listdir(clipPath)), temporal_dimension):\n",
        "            if ((count + 10) < len(os.listdir(clipPath))):\n",
        "                tempArr = os.listdir((inputData + \"/\" + labelFolder + \"/\" + clip))[count : (count + temporal_dimension)]\n",
        "                for i in range(len(tempArr)):\n",
        "                    tempArr[i] = inputData + \"/\" + labelFolder + \"/\" + clip + \"/\" + tempArr[i]\n",
        "                arrPaths.append(tempArr)\n",
        "                del tempArr\n",
        "                lbls.append(labelNumber[labelFolder])\n",
        "                count += temporal_dimension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEEDtLZU1Rse"
      },
      "source": [
        "# arrPaths and lbls are the lists of interest\n",
        "# arrPaths = [[imagePath1, imagePath2, ..., imagePath10], [imagePath1, imagePath2, ..., imagePath10] ... for all clips in video]\n",
        "# lbls = [label1, label2, label3, ... for each 10-frame clip in video]\n",
        "\n",
        "[x_train, x_test, y_train, y_test] = train_test_split(arrPaths, lbls, test_size = 0.25, shuffle = True, stratify = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfuPg0_c1qsn"
      },
      "source": [
        "# Create a generator for yielding batchSize number of 3D bundles (consisting of 10 images each)\n",
        "# Attach generator for train and test\n",
        "# Train 3DCNN with the train generator\n",
        "\n",
        "dataTrainPaths = [[x_train[i], y_train[i]] for i in range(len(y_train))]\n",
        "dataTestPaths = [[x_test[i], y_test[i]] for i in range(len(y_test))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsFFsQ9P1uqp"
      },
      "source": [
        "# Check if all arrPath elements have exactly 'temporal_dimension' image paths \n",
        "\n",
        "flag = 0\n",
        "temp = []\n",
        "for i in range(len(arrPaths)):\n",
        "    if (len(arrPaths[i]) != temporal_dimension):\n",
        "        flag = 1\n",
        "        temp.append(i)\n",
        "        # break\n",
        "\n",
        "if (flag == 1):\n",
        "    print(\"Not balanced.\")\n",
        "    print(temp)\n",
        "    print(len(temp))\n",
        "else:\n",
        "    print(\"Perfect.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shBI-UJX21o7"
      },
      "source": [
        "# Check if all x_train elements have exactly 'temporal_dimension' image paths \n",
        "\n",
        "# For DataTrainPaths\n",
        "flag = 0\n",
        "temp = 0\n",
        "for i in range(len(dataTrainPaths)):\n",
        "    if (len(dataTrainPaths[i][0]) != temporal_dimension):\n",
        "        flag = 1\n",
        "        temp = i\n",
        "        break\n",
        "\n",
        "if (flag == 1):\n",
        "    print(\"DataTrainPaths not balanced.\")\n",
        "    print(dataTrainPaths[temp][0])\n",
        "else:\n",
        "    print(\"DataTrainPaths Perfect.\")\n",
        "\n",
        "# For DataTestPaths\n",
        "flag = 0\n",
        "temp = 0\n",
        "for i in range(len(dataTestPaths)):\n",
        "    if (len(dataTestPaths[i][0]) != temporal_dimension):\n",
        "        flag = 1\n",
        "        temp = i\n",
        "        break\n",
        "\n",
        "if (flag == 1):\n",
        "    print(\"DataTestPaths not balanced.\")\n",
        "    print(dataTrainPaths[temp][0])\n",
        "else:\n",
        "    print(\"DataTestPaths Perfect.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpClBzeL2457"
      },
      "source": [
        "def data_generator(dataPaths, batch_size, sfl = True):              \n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    data is an array [[[frame1_filename,frame2_filename,…frame16_filename],label1], [[frame1_filename,frame2_filename,…frame16_filename],label2],……….].\n",
        "    \"\"\"\n",
        "    LABELS = [\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"]\n",
        "    num_samples = len(dataPaths)\n",
        "    \n",
        "    if sfl:\n",
        "        dataPaths = shuffle(dataPaths, random_state = 2)\n",
        "        \n",
        "    while True:   \n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # print('Starting index: ', offset) \n",
        "            \n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = dataPaths[offset : (offset + batch_size)]\n",
        "            \n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            Y_train = []\n",
        "            \n",
        "            # For each sample\n",
        "            for batch_sample in batch_samples:\n",
        "                # Load image paths (X)\n",
        "                x = batch_sample[0]\n",
        "                \n",
        "                # Read label (y)\n",
        "                y = batch_sample[1]\n",
        "                \n",
        "                temp_data_list = []\n",
        "                for img in x:\n",
        "                    try:\n",
        "                        # print(img.split('\\\\')[-1], \"\\n\")\n",
        "                        img = cv2.imread(img)\n",
        "                        img = cv2.resize(img, (224, 224))\n",
        "                        temp_data_list.append(img)\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        print('Error reading file: ', img)                      \n",
        "                \n",
        "                # Add sample to arrays\n",
        "                X_train.append(np.array(temp_data_list))\n",
        "                Y_train.append(y)\n",
        "    \n",
        "            # Make sure they're numpy arrays \n",
        "            X_train = np.array(X_train)\n",
        "            \n",
        "            #X_train = np.rollaxis(X_train,1,4)\n",
        "            Y_train = np.array(Y_train)\n",
        "            \n",
        "            # create one hot encoding for training in keras\n",
        "            Y_train = np_utils.to_categorical(Y_train, len(LABELS))\n",
        "    \n",
        "            # yield the next training batch            \n",
        "            yield X_train, Y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmC9sn8Y2-aX"
      },
      "source": [
        "train_generator = data_generator(dataTrainPaths, batch_size = 2)\n",
        "test_generator = data_generator(dataTestPaths, batch_size = 2)\n",
        "\n",
        "timepass_x, timepass_y = next(train_generator)\n",
        "\n",
        "print(\"Shape of X: \", timepass_x.shape)\n",
        "print(\"Shape of Y: \", timepass_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQFWnDq63BdN"
      },
      "source": [
        "x_0 = timepass_x[0]\n",
        "y_0 = timepass_y[0]\n",
        "\n",
        "print(\"Shape of X_0: \", x_0.shape)\n",
        "print(\"Shape of Y_0: \", y_0.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkEhGE7J3DZM"
      },
      "source": [
        "# Plotting the images in one 3D block (of 10 images)\n",
        "num_of_images = temporal_dimension\n",
        "LABELS = [\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"]\n",
        "\n",
        "# activity = LABELS[y_0.index(1)]\n",
        "fig = plt.figure(figsize = (8, 8)) \n",
        "\n",
        "# plt.title(\"One sample with {} frames | Activity: {}\".format(num_of_images, activity))\n",
        "plt.title(\"One sample with {} frames\".format(num_of_images))\n",
        "subplot_num = int(np.ceil(np.sqrt(num_of_images)))\n",
        "for i in range(int(num_of_images)):\n",
        "    ax = fig.add_subplot(subplot_num, subplot_num, i+1)\n",
        "    #ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n",
        "    ax.imshow(x_0[i,:,:,::-1])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('images_slowfusion.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Pn6NXq3FpS"
      },
      "source": [
        "print(set(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0k2GxrF3In3"
      },
      "source": [
        "LABELS = [\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"]\n",
        "testing = np_utils.to_categorical(y_train, len(LABELS))\n",
        "print(testing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTzcUaF53MIS"
      },
      "source": [
        "# Building and training the model\n",
        "from tensorflow.keras.layers import AveragePooling3D\n",
        "from tensorflow.keras.layers import Conv3D\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size = (3, 3, 4), strides = (1, 1, 2), input_shape = (temporal_dimension, 224, 224, 3), padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 2))\n",
        "model.add(AveragePooling3D(pool_size = (2, 2, 2), strides = None, padding = 'same'))\n",
        "model.add(Conv3D(16, kernel_size = (3, 3, 2), strides = (1, 1, 2), padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 2))\n",
        "model.add(AveragePooling3D(pool_size = (2, 2, 2), strides = None, padding = 'same'))\n",
        "model.add(Conv3D(16, kernel_size = (3, 3, 2), padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 2))\n",
        "model.add(AveragePooling3D(pool_size = (2, 2, 2), strides = None, padding = 'same'))\n",
        "\n",
        "# FC Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(len(LABELS), activation = 'softmax'))\n",
        "\n",
        "'''\n",
        "model.add(Conv3D(32, kernel_size = (3, 3, 3), input_shape = (10, 224, 224, 3), padding = 'same'))\n",
        "model\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "'''\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(), metrics=[tf.keras.metrics.Accuracy(),\n",
        "                                                                                 tf.keras.metrics.CategoricalAccuracy(),\n",
        "                                                                                 tf.keras.metrics.TopKCategoricalAccuracy(),\n",
        "                                                                                 tf.keras.metrics.Precision(),\n",
        "                                                                                 tf.keras.metrics.Recall(), \n",
        "                                                                                 tf.keras.metrics.TruePositives(), \n",
        "                                                                                 tf.keras.metrics.TrueNegatives(), \n",
        "                                                                                 tf.keras.metrics.FalsePositives(), \n",
        "                                                                                 tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "#plot_model(model, show_shapes = True, to_file = 'model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ4oBauS3PwK"
      },
      "source": [
        "# Saving checkpoints while training\n",
        "\n",
        "checkpointsPath = '/content/drive/MyDrive/Checkpoints/1st Colab Checkpoint/checkpoint.ckpt'\n",
        "\n",
        "checkpointCallback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpointsPath, \n",
        "                                                        save_best_only = False, \n",
        "                                                        save_weights_only = True, \n",
        "                                                        verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPrmxyPD3Qj6"
      },
      "source": [
        "# Training the model\n",
        "n_epochs = 25\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    H = model.fit(train_generator, \n",
        "                  steps_per_epoch = len(dataTrainPaths), \n",
        "                  epochs = n_epochs, \n",
        "                  validation_data = test_generator, \n",
        "                  validation_steps = len(dataTestPaths), \n",
        "                  callbacks = [checkpointCallback])\n",
        "    \n",
        "# Serialize the model to disk\n",
        "print(\"Serializing network...\")\n",
        "modelPath = '/content/drive/MyDrive/Saved Models/1st Colab Model/slowfusion_model'\n",
        "\n",
        "# Model can be saved in h5 or .savedmodel\n",
        "model.save(modelPath, save_format=\"h5\")\n",
        "print(\"Model serialized and saved.\\n\")\n",
        "\n",
        "\n",
        "# serialize the label binarizer to disk\n",
        "# lbPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models\\lb.pickle'\n",
        "# f = open(lbPath, \"wb\")\n",
        "# f.write(pickle.dumps(lb))\n",
        "# f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGRJzvKQ3el-"
      },
      "source": [
        "# Evaluate the network\n",
        "print(\"Evaluating network...\")\n",
        "predictions = model.predict(x = dataTestPaths.astype(\"float32\"), batch_size = 2)\n",
        "print(classification_report(testY.argmax(axis = 1), predictions.argmax(axis = 1), target_names = LABELS))\n",
        "\n",
        "# Plot the training loss and accuracy\n",
        "N = n_epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plotPath = '/content/drive/MyDrive/Plots/1st Colab Plot/slowfusion_trend.png'\n",
        "plt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}