{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Slow Fusion (Distributed Training).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newb-dev-1008/Human-PokeDex/blob/master/Slow%20Fusion%20-%20(Distributed%20Training%20-%202nd).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62KJgqMP8xJ7"
      },
      "source": [
        "# Tests to try\n",
        "# 1. Change in number of images per box (16)\n",
        "# 2. Kernel sizes\n",
        "# 3. Addition of Residual blocks\n",
        "# 4. Change in number of images per layer (from 2 to 4) in the temporal dimension\n",
        "# 5. Check the code for prediction in x_test\n",
        "# 6. Check out the graphs per epoch you want to plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15v0rmmyLvFD"
      },
      "source": [
        "# **Number of images: 16**\n",
        "With number of images per layer: 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhX2WtX69IS-",
        "outputId": "dd5f6c96-2e30-4875-e930-21e37125c82d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g9qBKCfzFtf"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2UAButA18i3",
        "outputId": "24dfd9c9-90a9-43cb-fa9c-4d89b0b1d3f5"
      },
      "source": [
        "# Check available TensorFlow devices\n",
        "from tensorflow import config\n",
        "config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WetCIkKf1EiQ"
      },
      "source": [
        "inputData = \"/content/drive/MyDrive/Datasets/Annotated\"\n",
        "arrPaths = []\n",
        "arrLbls = []\n",
        "lbls = []\n",
        "temporal_dimension = 10\n",
        "labelNumber = {\n",
        "    'Abuse' : 0,\n",
        "    'Assault' : 1,\n",
        "    'Fighting' : 2,\n",
        "    'Normal' : 3,\n",
        "    'Robbery' : 4,\n",
        "    'Vandalism' : 5\n",
        "}\n",
        "\n",
        "for labelFolder in os.listdir(inputData):\n",
        "    labelFolderPath = (inputData + \"/\" + labelFolder)\n",
        "    \n",
        "    for clip in os.listdir(labelFolderPath):\n",
        "        count = 0\n",
        "        clipPath = (inputData + \"/\" + labelFolder + \"/\" + clip)\n",
        "        \n",
        "        for frame in range(count, len(os.listdir(clipPath)), temporal_dimension):\n",
        "            if ((count + 10) < len(os.listdir(clipPath))):\n",
        "                tempArr = os.listdir((inputData + \"/\" + labelFolder + \"/\" + clip))[count : (count + temporal_dimension)]\n",
        "                for i in range(len(tempArr)):\n",
        "                    tempArr[i] = inputData + \"/\" + labelFolder + \"/\" + clip + \"/\" + tempArr[i]\n",
        "                arrPaths.append(tempArr)\n",
        "                del tempArr\n",
        "                lbls.append(labelNumber[labelFolder])\n",
        "                count += temporal_dimension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEEDtLZU1Rse"
      },
      "source": [
        "# arrPaths and lbls are the lists of interest\n",
        "# arrPaths = [[imagePath1, imagePath2, ..., imagePath10], [imagePath1, imagePath2, ..., imagePath10] ... for all clips in video]\n",
        "# lbls = [label1, label2, label3, ... for each 10-frame clip in video]\n",
        "\n",
        "[x_train, x_test, y_train, y_test] = train_test_split(arrPaths, lbls, test_size = 0.25, shuffle = True, stratify = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfuPg0_c1qsn"
      },
      "source": [
        "# Create a generator for yielding batchSize number of 3D bundles (consisting of 10 images each)\n",
        "# Attach generator for train and test\n",
        "# Train 3DCNN with the train generator\n",
        "\n",
        "dataTrainPaths = [[x_train[i], y_train[i]] for i in range(len(y_train))]\n",
        "dataTestPaths = [[x_test[i], y_test[i]] for i in range(len(y_test))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsFFsQ9P1uqp",
        "outputId": "6f744221-ff15-41f5-98ba-25db05b0b051"
      },
      "source": [
        "# Check if all arrPath elements have exactly 'temporal_dimension' image paths \n",
        "\n",
        "flag = 0\n",
        "temp = []\n",
        "for i in range(len(arrPaths)):\n",
        "    if (len(arrPaths[i]) != temporal_dimension):\n",
        "        flag = 1\n",
        "        temp.append(i)\n",
        "        # break\n",
        "\n",
        "if (flag == 1):\n",
        "    print(\"Not balanced.\")\n",
        "    print(temp)\n",
        "    print(len(temp))\n",
        "else:\n",
        "    print(\"Perfect.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perfect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shBI-UJX21o7",
        "outputId": "e72a68bf-4131-48aa-dbdc-2c4669855f76"
      },
      "source": [
        "# Check if all x_train elements have exactly 'temporal_dimension' image paths \n",
        "\n",
        "# For DataTrainPaths\n",
        "flag = 0\n",
        "temp = 0\n",
        "for i in range(len(dataTrainPaths)):\n",
        "    if (len(dataTrainPaths[i][0]) != temporal_dimension):\n",
        "        flag = 1\n",
        "        temp = i\n",
        "        break\n",
        "\n",
        "if (flag == 1):\n",
        "    print(\"DataTrainPaths not balanced.\")\n",
        "    print(dataTrainPaths[temp][0])\n",
        "else:\n",
        "    print(\"DataTrainPaths Perfect.\")\n",
        "\n",
        "# For DataTestPaths\n",
        "flag = 0\n",
        "temp = 0\n",
        "for i in range(len(dataTestPaths)):\n",
        "    if (len(dataTestPaths[i][0]) != temporal_dimension):\n",
        "        flag = 1\n",
        "        temp = i\n",
        "        break\n",
        "\n",
        "if (flag == 1):\n",
        "    print(\"DataTestPaths not balanced.\")\n",
        "    print(dataTrainPaths[temp][0])\n",
        "else:\n",
        "    print(\"DataTestPaths Perfect.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataTrainPaths Perfect.\n",
            "DataTestPaths Perfect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpClBzeL2457"
      },
      "source": [
        "def data_generator(dataPaths, batch_size, sfl = True):              \n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    data is an array [[[frame1_filename,frame2_filename,…frame16_filename],label1], [[frame1_filename,frame2_filename,…frame16_filename],label2],……….].\n",
        "    \"\"\"\n",
        "    LABELS = [\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"]\n",
        "    num_samples = len(dataPaths)\n",
        "    \n",
        "    if sfl:\n",
        "        dataPaths = shuffle(dataPaths, random_state = 2)\n",
        "        \n",
        "    while True:   \n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # print('Starting index: ', offset) \n",
        "            \n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = dataPaths[offset : (offset + batch_size)]\n",
        "            \n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            Y_train = []\n",
        "            \n",
        "            # For each sample\n",
        "            for batch_sample in batch_samples:\n",
        "                # Load image paths (X)\n",
        "                x = batch_sample[0]\n",
        "                \n",
        "                # Read label (y)\n",
        "                y = batch_sample[1]\n",
        "                \n",
        "                temp_data_list = []\n",
        "                for img in x:\n",
        "                    try:\n",
        "                        # print(img.split('\\\\')[-1], \"\\n\")\n",
        "                        img = cv2.imread(img)\n",
        "                        img = cv2.resize(img, (224, 224))\n",
        "                        temp_data_list.append(img)\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        print('Error reading file: ', img)                      \n",
        "                \n",
        "                # Add sample to arrays\n",
        "                X_train.append(np.array(temp_data_list))\n",
        "                Y_train.append(y)\n",
        "    \n",
        "            # Make sure they're numpy arrays \n",
        "            X_train = np.array(X_train)\n",
        "            \n",
        "            #X_train = np.rollaxis(X_train,1,4)\n",
        "            Y_train = np.array(Y_train)\n",
        "            \n",
        "            # create one hot encoding for training in keras\n",
        "            Y_train = np_utils.to_categorical(Y_train, len(LABELS))\n",
        "    \n",
        "            # yield the next training batch            \n",
        "            yield X_train, Y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmC9sn8Y2-aX",
        "outputId": "b59e9fcd-1433-4e9e-cfdc-ede3ee497347"
      },
      "source": [
        "train_generator = data_generator(dataTrainPaths, batch_size = 2)\n",
        "test_generator = data_generator(dataTestPaths, batch_size = 2)\n",
        "\n",
        "timepass_x, timepass_y = next(train_generator)\n",
        "\n",
        "print(\"Shape of X: \", timepass_x.shape)\n",
        "print(\"Shape of Y: \", timepass_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X:  (2, 10, 224, 224, 3)\n",
            "Shape of Y:  (2, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQFWnDq63BdN",
        "outputId": "da42ecee-f626-49af-cb3a-3630b832b8d1"
      },
      "source": [
        "x_0 = timepass_x[0]\n",
        "y_0 = timepass_y[0]\n",
        "\n",
        "print(\"Shape of X_0: \", x_0.shape)\n",
        "print(\"Shape of Y_0: \", y_0.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_0:  (10, 224, 224, 3)\n",
            "Shape of Y_0:  (6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkEhGE7J3DZM"
      },
      "source": [
        "# Plotting the images in one 3D block (of 10 images)\n",
        "num_of_images = temporal_dimension\n",
        "LABELS = [\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"]\n",
        "\n",
        "# activity = LABELS[y_0.index(1)]\n",
        "fig = plt.figure(figsize = (8, 8)) \n",
        "\n",
        "# plt.title(\"One sample with {} frames | Activity: {}\".format(num_of_images, activity))\n",
        "plt.title(\"One sample with {} frames\".format(num_of_images))\n",
        "subplot_num = int(np.ceil(np.sqrt(num_of_images)))\n",
        "for i in range(int(num_of_images)):\n",
        "    ax = fig.add_subplot(subplot_num, subplot_num, i+1)\n",
        "    #ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n",
        "    ax.imshow(x_0[i,:,:,::-1])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('/content/drive/MyDrive/images_slowfusion-2nd.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Pn6NXq3FpS",
        "outputId": "aab13931-46dd-4615-da8c-3c9746f1f7f2"
      },
      "source": [
        "print(set(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0k2GxrF3In3",
        "outputId": "b72ab7f1-6748-41a7-ed72-c4d52d78179d"
      },
      "source": [
        "LABELS = [\"Abuse\", \"Assault\", \"Fighting\", \"Normal\", \"Robbery\", \"Vandalism\"]\n",
        "testing = np_utils.to_categorical(y_train, len(LABELS))\n",
        "print(testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTzcUaF53MIS",
        "outputId": "47bc65ad-e329-4026-b79c-f52abdbaa03f"
      },
      "source": [
        "# Building and training the model\n",
        "from tensorflow.keras.layers import AveragePooling3D\n",
        "from tensorflow.keras.layers import Conv3D\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size = (3, 3, 4), strides = (1, 1, 2), input_shape = (temporal_dimension, 224, 224, 3), padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 2))\n",
        "model.add(AveragePooling3D(pool_size = (2, 2, 2), strides = None, padding = 'same'))\n",
        "model.add(Conv3D(16, kernel_size = (3, 3, 2), strides = (1, 1, 2), padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 2))\n",
        "model.add(AveragePooling3D(pool_size = (2, 2, 2), strides = None, padding = 'same'))\n",
        "model.add(Conv3D(16, kernel_size = (3, 3, 2), padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 2))\n",
        "model.add(AveragePooling3D(pool_size = (2, 2, 2), strides = None, padding = 'same'))\n",
        "\n",
        "# FC Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(len(LABELS), activation = 'softmax'))\n",
        "\n",
        "'''\n",
        "model.add(Conv3D(32, kernel_size = (3, 3, 3), input_shape = (10, 224, 224, 3), padding = 'same'))\n",
        "model\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "'''\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(), metrics=[tf.keras.metrics.Accuracy(),\n",
        "                                                                                 tf.keras.metrics.CategoricalAccuracy(),\n",
        "                                                                                 tf.keras.metrics.TopKCategoricalAccuracy(),\n",
        "                                                                                 tf.keras.metrics.Precision(),\n",
        "                                                                                 tf.keras.metrics.Recall(), \n",
        "                                                                                 tf.keras.metrics.TruePositives(), \n",
        "                                                                                 tf.keras.metrics.TrueNegatives(), \n",
        "                                                                                 tf.keras.metrics.FalsePositives(), \n",
        "                                                                                 tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "#plot_model(model, show_shapes = True, to_file = 'model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 10, 224, 112, 32)  3488      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 10, 224, 112, 32)  896       \n",
            "_________________________________________________________________\n",
            "average_pooling3d (AveragePo (None, 5, 112, 56, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 5, 112, 28, 16)    9232      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 5, 112, 28, 16)    448       \n",
            "_________________________________________________________________\n",
            "average_pooling3d_1 (Average (None, 3, 56, 14, 16)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 3, 56, 14, 16)     4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 3, 56, 14, 16)     224       \n",
            "_________________________________________________________________\n",
            "average_pooling3d_2 (Average (None, 2, 28, 7, 16)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 3,233,766\n",
            "Trainable params: 3,232,982\n",
            "Non-trainable params: 784\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ4oBauS3PwK"
      },
      "source": [
        "# Saving checkpoints while training\n",
        "\n",
        "checkpointsPath = '/content/drive/MyDrive/Checkpoints/2nd Colab Checkpoint/checkpoint.ckpt'\n",
        "\n",
        "checkpointCallback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpointsPath, \n",
        "                                                        save_best_only = False, \n",
        "                                                        save_weights_only = True, \n",
        "                                                        verbose = 1)\n",
        "tensorboardCallback = tf.keras.callbacks.TensorBoard(log_dir = \"/content/drive/MyDrive/Checkpoints/2nd Colab Checkpoint/TensorBoard Logs\",\n",
        "                                                    write_graph = True,\n",
        "                                                    update_freq = 'epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JPrmxyPD3Qj6",
        "outputId": "46084802-ff7e-4de7-d059-ff57cb619b1c"
      },
      "source": [
        "# Training the model\n",
        "n_epochs = 50\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    H = model.fit(train_generator, \n",
        "                  steps_per_epoch = len(dataTrainPaths), \n",
        "                  epochs = n_epochs, \n",
        "                  validation_data = test_generator, \n",
        "                  validation_steps = len(dataTestPaths), \n",
        "                  callbacks = [checkpointCallback, tensorboardCallback])\n",
        "    \n",
        "# Serialize the model to disk\n",
        "print(\"Serializing network...\")\n",
        "modelPath = '/content/drive/MyDrive/Saved Models/2nd Colab Model/slowfusion_model'\n",
        "\n",
        "# Model can be saved in h5 or .savedmodel\n",
        "model.save(modelPath, save_format=\"h5\")\n",
        "print(\"Model serialized and saved.\\n\")\n",
        "\n",
        "\n",
        "# serialize the label binarizer to disk\n",
        "# lbPath = r'C:\\Users\\Yash Umale\\Documents\\6th Sem\\Open Lab\\Python Files\\Crime Detection\\Models\\lb.pickle'\n",
        "# f = open(lbPath, \"wb\")\n",
        "# f.write(pickle.dumps(lb))\n",
        "# f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  15/3894 [..............................] - ETA: 14:29:53 - loss: 7.1873 - accuracy: 0.0000e+00 - categorical_accuracy: 0.3667 - top_k_categorical_accuracy: 0.8000 - precision: 0.3929 - recall: 0.3667 - true_positives: 11.0000 - true_negatives: 133.0000 - false_positives: 17.0000 - false_negatives: 19.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-671d8dbde9c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTestPaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   callbacks = [checkpointCallback, tensorboardCallback])\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Serialize the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFwcZScAURiP"
      },
      "source": [
        "# Saving the history object of trained model\n",
        "import json\n",
        "history_dict = H.history\n",
        "\n",
        "# Save it under the form of a json file\n",
        "JSON_path = '/content/drive/MyDrive/Checkpoints/2nd Colab Checkpoint/History/history.json'\n",
        "json.dump(history_dict, open(JSON_path, 'w'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGRJzvKQ3el-"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "N = n_epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plotPath = '/content/drive/MyDrive/Plots/2nd Colab Plot/slowfusion_trend.png'\n",
        "plt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ4hDltgUTur"
      },
      "source": [
        "# Invoke the saved model for evaluation\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "savedModelPath = '/content/drive/MyDrive/Saved Models/2nd Colab Model/slowfusion_model'\n",
        "savedModel = load_model(savedModelPath)\n",
        "savedModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCNE7mhxUVsA"
      },
      "source": [
        "# Evaluate the network\n",
        "\n",
        "print(\"Evaluating network...\")\n",
        "predictions = savedModel.predict(test_generator)\n",
        "print(classification_report(y_test.argmax(axis = 1), predictions.argmax(axis = 1), target_names = LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}